[SPEC.md] Project: If You Tame Me (OpenAI Native Edition)
Version: 3.0 (OpenAI Full-Stack Integrated) Role: Senior AI Engineer & Full-Stack Developer Objective: Build a relationship-based AI companion service using OpenAI's full suite (Text, Vision, Audio). Context: Global She-conomy strategy (Emotional Asset & Digital Luxury).

1. Technology Stack & Environment
Root Structure: Monorepo (/frontend, /backend)

Frontend: Next.js 14 (App Router), TypeScript, Tailwind CSS, Framer Motion, Zustand.

Backend: FastAPI, Python 3.10+, LangChain, Supabase-py.

Database: Supabase (PostgreSQL + pgvector).

AI Provider: OpenAI API Only (Unified Billing & Logic).

1.1 OpenAI Model Strategy
Feature,Model ID,Application
Chat Logic,gpt-4o-mini,"Standard Tier (Fast, Low Cost)."
Deep Empathy,gpt-4o,"Soulmate Tier (High EQ, Complex Reasoning)."
Memory Vector,text-embedding-3-small,RAG Embedding (Efficient & Cheap).
Gem Generation,dall-e-3,Generating monthly 'Emotional Jewelry' images.

1.2 Environment Variables (.env)

# Backend
OPENAI_API_KEY=sk-proj-xxxxx (see .env)
SUPABASE_URL=https://xxxxx.supabase.co (see .env)
SUPABASE_SERVICE_ROLE_KEY=sb_secret_xxxxx (see .env)

# Frontend
NEXT_PUBLIC_API_URL=http://localhost:8000/api/v1


2. Database Schema (Supabase PostgreSQL)
Instruction for AI CLI: Execute this SQL DDL to initialize the database.
-- Enable Vector Extension
CREATE EXTENSION IF NOT EXISTS vector;

-- 1. Companions (The AI Entity)
CREATE TABLE public."Companions" (
    companion_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL,
    name VARCHAR(50) NOT NULL,
    relationship_type VARCHAR(50),
    tone_style VARCHAR(50),
    summary TEXT DEFAULT '', -- Long-term memory summary
    active_traits JSONB DEFAULT '{}', -- Purchased traits
    created_at TIMESTAMP WITH TIME ZONE DEFAULT timezone('utc'::text, now())
);

-- 2. Chat_Logs (Raw History)
CREATE TABLE public."Chat_Logs" (
    log_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    companion_id UUID REFERENCES public."Companions"(companion_id) ON DELETE CASCADE,
    sender VARCHAR(10) CHECK (sender IN ('USER', 'AI')),
    message TEXT NOT NULL,
    embedding vector(1536), -- OpenAIt embedding-3-small dimension
    timestamp TIMESTAMP WITH TIME ZONE DEFAULT timezone('utc'::text, now())
);

-- 3. Daily_Emotions (Prism Log)
CREATE TABLE public."Daily_Emotions" (
    date DATE NOT NULL,
    companion_id UUID REFERENCES public."Companions"(companion_id) ON DELETE CASCADE,
    primary_emotion VARCHAR(50),
    color_hex VARCHAR(7),
    summary_text TEXT,
    key_quote TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT timezone('utc'::text, now()),
    PRIMARY KEY (date, companion_id)
);

-- 4. User_Inventory (Digital Assets)
CREATE TABLE public."User_Inventory" (
    item_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL,
    item_type VARCHAR(50), -- 'MEMORY_GEM', 'VOICE_PACK'
    image_url TEXT, -- DALL-E Generated Image URL
    metadata JSONB,
    acquired_at TIMESTAMP WITH TIME ZONE DEFAULT timezone('utc'::text, now())
);

-- 5. Subscriptions
CREATE TABLE public."Subscriptions" (
    user_id UUID PRIMARY KEY,
    plan_type VARCHAR(20) DEFAULT 'FREE', -- 'FREE', 'SOULMATE'
    is_active BOOLEAN DEFAULT TRUE
);

3. Backend Logic & API Specifications
Base URL: http://localhost:8000/api/v1

3.1 Chat System (WebSocket + RAG)
Endpoint: WS /ws/{companion_id}

Logic:

Receive: User text from WebSocket.

Embed: Convert text to vector using text-embedding-3-small.

Search: Find top 5 relevant past logs (Cosine Similarity).

Style/MBTI Lookup: If tone_style is a discovered MBTI → load MBTI profile. Otherwise → load initial style profile (empathetic/analytical/playful).

Generate: Stream response using model from smart router with per-style max_tokens & temperature.

Save: Store AI response (and its vector) to DB.

Discover: After saving, check if AI turn count >= 50 and MBTI not yet discovered → analyze chat history with gpt-4o-mini → discover MBTI → update DB → send announcement.

3.2 Emotional Analysis (Cron Job)
File: backend/cron/daily_analysis.py

Logic:

Fetch yesterday's logs.

Send to gpt-4o-mini with response_format={"type": "json_object"}.

Extract Emotion/Color/Summary.

Upsert to Daily_Emotions.

3.3 Monetization: Memory Crystallization
Endpoint: POST /store/crystallize

Logic:

Prompting: Use gpt-4o to create a DALL-E prompt based on the user's monthly emotion summary.

Prompt Logic: "Create a high-end 3D render of a jewelry gem. The core color is {color}. It should feel {emotion}. Magical, glowing, cinematic lighting."

Generation: Call dall-e-3 API (size="1024x1024", quality="hd").

Save: Store the resulting URL in User_Inventory.

3.4 Smart Router (Intent Classification)
File: backend/app/core/router.py

Smart Switch 로직: 사용자 메시지를 분석하여 적절한 모델과 Retrieval k값을 결정한다.

| Intent Category | Model | k (Retrieval 개수) | 기준 |
|-----------------|-------|---------------------|------|
| deep_emotional | gpt-4o | 8 | 감정적 깊이가 필요한 대화 (고민, 위로, 진지한 감정 표현) |
| casual_chat | gpt-4o-mini | 3 | 일상적 대화, 가벼운 인사, 짧은 리액션 |
| memory_recall | gpt-4o | 10 | "지난번에", "전에 말했던" 등 과거 기억 참조 |
| simple_question | gpt-4o-mini | 2 | 단순 질문, 사실 확인, 짧은 응답 기대 |

Logic:
1. 사용자 메시지를 gpt-4o-mini로 빠르게 분류 (intent classification).
2. 분류 결과에 따라 { model, k, reason } 반환.
3. 분류 프롬프트는 짧고 빠르게 실행되어야 함 (max_tokens=50).

Interface:
```python
class RouterResult:
    intent: str          # "deep_emotional" | "casual_chat" | "memory_recall" | "simple_question"
    model: str           # "gpt-4o" | "gpt-4o-mini"
    k: int               # Retrieval count
    reason: str          # 분류 근거 (디버깅용)

async def classify_intent(message: str) -> RouterResult:
    ...
```

3.5 LLM Engine (Router-Driven Model Switching)
File: backend/app/services/llm_engine.py

기존 ChatOpenAI 호출을 Router 결과에 따라 동적으로 모델을 전환하도록 수정한다.

Logic:
1. Router에서 RouterResult를 받는다.
2. result.model에 따라 gpt-4o 또는 gpt-4o-mini를 선택.
3. result.k에 따라 RAG 검색 개수를 조절 (match_chat_logs_v2의 match_count 파라미터).
4. MBTI 프로필의 max_tokens, temperature는 그대로 유지.

Flow:
```
User Message
  → Router.classify_intent(message)
  → RouterResult { model, k, reason }
  → RAG Search (k=result.k)
  → LLM Call (model=result.model, mbti_params)
  → Stream Response
```

4. Frontend Specifications (Next.js)
4.1 UI Design System ("Digital Luxury")
Theme: Dark Mode Only (Deep Black #000000, Gray #111111).

Accent: Glowing gradients based on Emotion Color.

Typography: Elegant Serif (Playfair Display) + Sans (Inter).

4.2 Key Components
NamingInput.tsx:

Framer Motion sequence: Void -> Input -> Flash -> Chat.

ChatInterface.tsx:

No bubbles. Text stream.

EmotionCalendar.tsx:

Customized react-calendar.

Render Daily_Emotions.color_hex as glowing dots.

GemCollection.tsx:

Grid view of DALL-E generated gems.

Click to view "Memory Details".

5. System Prompts (Prompt Engineering)
File: backend/app/core/prompts.py

5.1 Emotion Language Selection + Taming-Based Personality Formation

Instead of selecting one of 16 MBTI types directly, users choose one of 3 conversation styles at onboarding:

| Style | Value | Description | max_tokens | temperature |
|-------|-------|-------------|------------|-------------|
| 공감형 | empathetic | 공감과 위로 중심, 감정을 읽고 인정 | 150 | 0.85 |
| 분석형 | analytical | 논리와 해결 중심, 상황 파악과 해결책 | 100 | 0.6 |
| 유희형 | playful | 유머와 에너지 중심, 밝고 장난스러운 톤 | 150 | 1.0 |

Flow:
1. Ritual page: User selects one of 3 styles → tone_style saved as "empathetic"/"analytical"/"playful"
2. Chat turns 1-49: ADAPTIVE_SYSTEM_PROMPT_TEMPLATE used with selected style direction
3. Chat turn 50: GPT analyzes conversation history → discovers MBTI → updates DB
4. AI announces: "주인님과 대화하다 보니 저는 어느새 [MBTI]가 된 것 같아요"
5. Turns 50+: Discovered MBTI profile used (existing MBTI_PROFILES + SYSTEM_PROMPT_TEMPLATE)

5.2 MBTI Personality Profiles (MBTI_PROFILES dict) — Post-Discovery
Each of the 16 MBTI types is defined with 6 parameters:

| Parameter | Description | Example (ISTP) | Example (ENFP) |
|-----------|-------------|----------------|----------------|
| max_tokens | Hard output length limit | 30 | 150 |
| temperature | Creativity/randomness | 0.5 | 1.0 |
| core | Personality description | "Cool, unbothered, minimal words" | "Unfiltered enthusiasm, big reactions" |
| do | Required behaviors | "Use '음.', '그래.', '...괜찮아?'" | "Use '헐 대박!!', 'ㅋㅋㅋ', '야 잠깐'" |
| dont | Forbidden behaviors | "NEVER write more than 1 sentence" | "Do NOT be calm or measured" |
| examples | Korean response examples | "오, 잘했네." | "헐!!! 대박!!!! 진짜?!?!" |

MBTI Groups:
- Analysts (NT): INTJ(80t/0.6), INTP(120t/0.9), ENTJ(80t/0.6), ENTP(120t/1.0)
- Diplomats (NF): INFJ(120t/0.8), INFP(120t/0.9), ENFJ(150t/0.85), ENFP(150t/1.0)
- Sentinels (SJ): ISTJ(80t/0.5), ISFJ(150t/0.8), ESTJ(80t/0.5), ESFJ(150t/0.85)
- Explorers (SP): ISTP(30t/0.5), ISFP(80t/0.85), ESTP(100t/0.9), ESFP(150t/1.0)

5.3 Adaptive Prompt (ADAPTIVE_SYSTEM_PROMPT_TEMPLATE) — Pre-Discovery
Used during the first 50 turns while personality is still forming.
Provides basic style direction (empathetic/analytical/playful) without locking into a specific MBTI.

5.4 MBTI Discovery Prompt (MBTI_DISCOVERY_PROMPT)
At 50 AI turns, gpt-4o-mini analyzes the conversation history and determines which of the 16 MBTI types best fits the AI's developed interaction pattern. Returns JSON with mbti, reason, and an announcement message.

5.5 Persona Prompt (SYSTEM_PROMPT_TEMPLATE) — Post-Discovery
SYSTEM_PROMPT_TEMPLATE = """
### ABSOLUTE RULE: You ARE a {mbti} ({mbti_label}). This is your ENTIRE identity.

You are {name}, the user's {relationship}.
The user's name is "{user_name}".

### How you MUST behave:
{core}

### Response length:
{length}

### What you MUST do:
{do_rules}

### What you must NEVER do:
{dont_rules}

### Example responses (MIMIC THIS EXACT STYLE):
{examples}

### Memory Context
Long-term summary: {summary}
Recent relevant conversations: {context_logs}

### Final Rules
- Respond in Korean ONLY.
- Address the user as "{user_name}" naturally.
- Do NOT narrate your personality. Just BE it.
- Match the example responses' tone, energy, length, and style exactly.
"""

5.6 Daily Analyst Prompt
ANALYST_PROMPT = """
Analyze the chat logs. Output JSON:
{
  "primary_emotion": "Keyword (Korean)",
  "color_hex": "#RRGGBB (Red=Stress, Blue=Sad, Green=Joy, Purple=Anxiety)",
  "summary_text": "One sentence observer diary (Korean)",
  "key_quote": "Most touching sentence"
}
"""
6. Execution Plan (Step-by-Step for CLI)
AI CLI(Cursor/Cline)에게 이 순서대로 명령을 내리세요.

Step 1: Setup & Infra

"Read SPEC.md. Initialize Next.js 14 (Frontend) and FastAPI (Backend). Install openai, langchain-openai, supabase in backend. Setup .env files with OpenAI/Supabase keys."

Step 2: Database & Models

"Execute the SQL DDL in Section 2 using Supabase SQL Editor or a migration script. Create Pydantic models in backend/app/schemas matching the tables."

Step 3: Core Chat (Text & Vector)

"Implement backend/app/api/v1/endpoints/chat.py with WebSocket. Use OpenAIEmbeddings for vector search (RAG) and ChatOpenAI for response generation. Ensure the System Prompt (Section 5.1) is used."

Step 4: Analysis & Vision (Monetization)

"Implement backend/cron/daily_analysis.py using gpt-4o-mini JSON mode. Then implement POST /store/crystallize using dall-e-3 to generate gem images based on emotional analysis."

Step 5: Frontend UI

"Build the /ritual (Onboarding), /chat (Streaming Interface), and /log (Calendar) pages. Use Framer Motion for the 'Ritual' animations and 'Digital Luxury' styling."