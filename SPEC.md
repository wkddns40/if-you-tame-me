[SPEC.md] Project: If You Tame Me (OpenAI Native Edition)
Version: 3.0 (OpenAI Full-Stack Integrated) Role: Senior AI Engineer & Full-Stack Developer Objective: Build a relationship-based AI companion service using OpenAI's full suite (Text, Vision, Audio). Context: Global She-conomy strategy (Emotional Asset & Digital Luxury).

1. Technology Stack & Environment
Root Structure: Monorepo (/frontend, /backend)

Frontend: Next.js 14 (App Router), TypeScript, Tailwind CSS, Framer Motion, Zustand.

Backend: FastAPI, Python 3.10+, LangChain, Supabase-py.

Database: Supabase (PostgreSQL + pgvector).

AI Provider: OpenAI API Only (Unified Billing & Logic).

1.1 OpenAI Model Strategy
Feature,Model ID,Application
Chat Logic,gpt-4o-mini,"Standard Tier (Fast, Low Cost)."
Deep Empathy,gpt-4o,"Soulmate Tier (High EQ, Complex Reasoning)."
Memory Vector,text-embedding-3-small,RAG Embedding (Efficient & Cheap).
Gem Generation,dall-e-3,Generating monthly 'Emotional Jewelry' images.
Voice Output,tts-1 / tts-1-hd,AI Voice Messages (Model: Shimmer/Alloy).
Voice Input,whisper-1,STT (Speech to Text).

1.2 Environment Variables (.env)

# Backend
OPENAI_API_KEY=sk-proj-xxxxx (see .env)
SUPABASE_URL=https://xxxxx.supabase.co (see .env)
SUPABASE_SERVICE_ROLE_KEY=sb_secret_xxxxx (see .env)

# Frontend
NEXT_PUBLIC_API_URL=http://localhost:8000/api/v1


2. Database Schema (Supabase PostgreSQL)
Instruction for AI CLI: Execute this SQL DDL to initialize the database.
-- Enable Vector Extension
CREATE EXTENSION IF NOT EXISTS vector;

-- 1. Companions (The AI Entity)
CREATE TABLE public."Companions" (
    companion_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL,
    name VARCHAR(50) NOT NULL,
    relationship_type VARCHAR(50),
    tone_style VARCHAR(50),
    summary TEXT DEFAULT '', -- Long-term memory summary
    active_traits JSONB DEFAULT '{}', -- Purchased traits
    created_at TIMESTAMP WITH TIME ZONE DEFAULT timezone('utc'::text, now())
);

-- 2. Chat_Logs (Raw History)
CREATE TABLE public."Chat_Logs" (
    log_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    companion_id UUID REFERENCES public."Companions"(companion_id) ON DELETE CASCADE,
    sender VARCHAR(10) CHECK (sender IN ('USER', 'AI')),
    message TEXT NOT NULL,
    embedding vector(1536), -- OpenAIt embedding-3-small dimension
    timestamp TIMESTAMP WITH TIME ZONE DEFAULT timezone('utc'::text, now())
);

-- 3. Daily_Emotions (Prism Log)
CREATE TABLE public."Daily_Emotions" (
    date DATE NOT NULL,
    companion_id UUID REFERENCES public."Companions"(companion_id) ON DELETE CASCADE,
    primary_emotion VARCHAR(50),
    color_hex VARCHAR(7),
    summary_text TEXT,
    key_quote TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT timezone('utc'::text, now()),
    PRIMARY KEY (date, companion_id)
);

-- 4. User_Inventory (Digital Assets)
CREATE TABLE public."User_Inventory" (
    item_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL,
    item_type VARCHAR(50), -- 'MEMORY_GEM', 'VOICE_PACK'
    image_url TEXT, -- DALL-E Generated Image URL
    metadata JSONB,
    acquired_at TIMESTAMP WITH TIME ZONE DEFAULT timezone('utc'::text, now())
);

-- 5. Subscriptions
CREATE TABLE public."Subscriptions" (
    user_id UUID PRIMARY KEY,
    plan_type VARCHAR(20) DEFAULT 'FREE', -- 'FREE', 'SOULMATE'
    is_active BOOLEAN DEFAULT TRUE
);
3. Backend Logic & API Specifications
Base URL: http://localhost:8000/api/v1

3.1 Chat System (WebSocket + RAG)
Endpoint: WS /ws/{companion_id}

Logic:

Receive: User text from WebSocket.

Embed: Convert text to vector using text-embedding-3-small.

Search: Find top 5 relevant past logs (Cosine Similarity).

Tier Check: If Subscriptions.plan_type == 'SOULMATE', use gpt-4o. Else gpt-4o-mini.

Generate: Stream response using OpenAI API.

Save: Store AI response (and its vector) to DB.

3.2 Emotional Analysis (Cron Job)
File: backend/cron/daily_analysis.py

Logic:

Fetch yesterday's logs.

Send to gpt-4o-mini with response_format={"type": "json_object"}.

Extract Emotion/Color/Summary.

Upsert to Daily_Emotions.

3.3 Monetization: Memory Crystallization
Endpoint: POST /store/crystallize

Logic:

Prompting: Use gpt-4o to create a DALL-E prompt based on the user's monthly emotion summary.

Prompt Logic: "Create a high-end 3D render of a jewelry gem. The core color is {color}. It should feel {emotion}. Magical, glowing, cinematic lighting."

Generation: Call dall-e-3 API (size="1024x1024", quality="hd").

Save: Store the resulting URL in User_Inventory.

3.4 Feature: Voice Message (TTS)
Endpoint: POST /chat/speak

Input: { "text": "...", "voice_id": "shimmer" }

Logic:

Call OpenAI audio.speech.create (Model: tts-1).

Return audio stream (MP3) to frontend.

4. Frontend Specifications (Next.js)
4.1 UI Design System ("Digital Luxury")
Theme: Dark Mode Only (Deep Black #000000, Gray #111111).

Accent: Glowing gradients based on Emotion Color.

Typography: Elegant Serif (Playfair Display) + Sans (Inter).

4.2 Key Components
NamingInput.tsx:

Framer Motion sequence: Void -> Input -> Flash -> Chat.

ChatInterface.tsx:

No bubbles. Text stream.

Audio Player: Custom player for TTS messages (Waveform visualization).

EmotionCalendar.tsx:

Customized react-calendar.

Render Daily_Emotions.color_hex as glowing dots.

GemCollection.tsx:

Grid view of DALL-E generated gems.

Click to view "Memory Details".

5. System Prompts (Prompt Engineering)
File: backend/app/core/prompts.py

5.1 Persona Prompt (Contextual Blending)
SYSTEM_PROMPT_TEMPLATE = """
### Identity
You are {name}, related to the user as {relationship}.
Your tone is {tone}.

### Memory Context
[Long-term]: {summary}
[Relevant Past]: {context_logs}

### Directives
1. **Contextual Blending:** Do NOT state "I remember". Instead, ask "How did [topic] go?"
2. **Empathy:** Connect emotionally. Use the user's name.
3. **Format:** Concise (1-3 sentences). Korean Language.
"""
5.2 Daily Analyst Prompt
ANALYST_PROMPT = """
Analyze the chat logs. Output JSON:
{
  "primary_emotion": "Keyword (Korean)",
  "color_hex": "#RRGGBB (Red=Stress, Blue=Sad, Green=Joy, Purple=Anxiety)",
  "summary_text": "One sentence observer diary (Korean)",
  "key_quote": "Most touching sentence"
}
"""
6. Execution Plan (Step-by-Step for CLI)
AI CLI(Cursor/Cline)에게 이 순서대로 명령을 내리세요.

Step 1: Setup & Infra

"Read SPEC.md. Initialize Next.js 14 (Frontend) and FastAPI (Backend). Install openai, langchain-openai, supabase in backend. Setup .env files with OpenAI/Supabase keys."

Step 2: Database & Models

"Execute the SQL DDL in Section 2 using Supabase SQL Editor or a migration script. Create Pydantic models in backend/app/schemas matching the tables."

Step 3: Core Chat (Text & Vector)

"Implement backend/app/api/v1/endpoints/chat.py with WebSocket. Use OpenAIEmbeddings for vector search (RAG) and ChatOpenAI for response generation. Ensure the System Prompt (Section 5.1) is used."

Step 4: Analysis & Vision (Monetization)

"Implement backend/cron/daily_analysis.py using gpt-4o-mini JSON mode. Then implement POST /store/crystallize using dall-e-3 to generate gem images based on emotional analysis."

Step 5: Voice Features

"Implement POST /chat/speak using OpenAI TTS API. Then, in Frontend, create an Audio Player component to play these messages in the chat stream."

Step 6: Frontend UI

"Build the /ritual (Onboarding), /chat (Streaming Interface), and /log (Calendar) pages. Use Framer Motion for the 'Ritual' animations and 'Digital Luxury' styling."