[SPEC.md] Project: If You Tame Me (OpenAI Native Edition)
Version: 3.0 (OpenAI Full-Stack Integrated) Role: Senior AI Engineer & Full-Stack Developer Objective: Build a relationship-based AI companion service using OpenAI's full suite (Text, Vision, Audio). Context: Global She-conomy strategy (Emotional Asset & Digital Luxury).

1. Technology Stack & Environment
Root Structure: Monorepo (/frontend, /backend)

Frontend: Next.js 14 (App Router), TypeScript, Tailwind CSS, Framer Motion, Zustand.

Backend: FastAPI, Python 3.10+, LangChain, Supabase-py.

Database: Supabase (PostgreSQL + pgvector).

AI Provider: OpenAI API Only (Unified Billing & Logic).

1.1 OpenAI Model Strategy
Feature,Model ID,Application
Chat Logic,gpt-4o-mini,"Standard Tier (Fast, Low Cost)."
Deep Empathy,gpt-4o,"Soulmate Tier (High EQ, Complex Reasoning)."
Memory Vector,text-embedding-3-small,RAG Embedding (Efficient & Cheap).
Gem Generation,dall-e-3,Generating monthly 'Emotional Jewelry' images.
Voice Output,tts-1 / tts-1-hd,AI Voice Messages (Model: Shimmer/Alloy).
Voice Input,whisper-1,STT (Speech to Text).

1.2 Environment Variables (.env)

# Backend
OPENAI_API_KEY=sk-proj-xxxxx (see .env)
SUPABASE_URL=https://xxxxx.supabase.co (see .env)
SUPABASE_SERVICE_ROLE_KEY=sb_secret_xxxxx (see .env)

# Frontend
NEXT_PUBLIC_API_URL=http://localhost:8000/api/v1


2. Database Schema (Supabase PostgreSQL)
Instruction for AI CLI: Execute this SQL DDL to initialize the database.
-- Enable Vector Extension
CREATE EXTENSION IF NOT EXISTS vector;

-- 1. Companions (The AI Entity)
CREATE TABLE public."Companions" (
    companion_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL,
    name VARCHAR(50) NOT NULL,
    relationship_type VARCHAR(50),
    tone_style VARCHAR(50),
    summary TEXT DEFAULT '', -- Long-term memory summary
    active_traits JSONB DEFAULT '{}', -- Purchased traits
    created_at TIMESTAMP WITH TIME ZONE DEFAULT timezone('utc'::text, now())
);

-- 2. Chat_Logs (Raw History)
CREATE TABLE public."Chat_Logs" (
    log_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    companion_id UUID REFERENCES public."Companions"(companion_id) ON DELETE CASCADE,
    sender VARCHAR(10) CHECK (sender IN ('USER', 'AI')),
    message TEXT NOT NULL,
    embedding vector(1536), -- OpenAIt embedding-3-small dimension
    timestamp TIMESTAMP WITH TIME ZONE DEFAULT timezone('utc'::text, now())
);

-- 3. Daily_Emotions (Prism Log)
CREATE TABLE public."Daily_Emotions" (
    date DATE NOT NULL,
    companion_id UUID REFERENCES public."Companions"(companion_id) ON DELETE CASCADE,
    primary_emotion VARCHAR(50),
    color_hex VARCHAR(7),
    summary_text TEXT,
    key_quote TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT timezone('utc'::text, now()),
    PRIMARY KEY (date, companion_id)
);

-- 4. User_Inventory (Digital Assets)
CREATE TABLE public."User_Inventory" (
    item_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL,
    item_type VARCHAR(50), -- 'MEMORY_GEM', 'VOICE_PACK'
    image_url TEXT, -- DALL-E Generated Image URL
    metadata JSONB,
    acquired_at TIMESTAMP WITH TIME ZONE DEFAULT timezone('utc'::text, now())
);

-- 5. Subscriptions
CREATE TABLE public."Subscriptions" (
    user_id UUID PRIMARY KEY,
    plan_type VARCHAR(20) DEFAULT 'FREE', -- 'FREE', 'SOULMATE'
    is_active BOOLEAN DEFAULT TRUE
);
-- 6. TTS_Cache (Hash-based TTS Audio Cache)
CREATE TABLE public."TTS_Cache" (
    cache_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    text_hash VARCHAR(64) NOT NULL UNIQUE,  -- SHA-256 hash of (text + voice_id)
    voice_id VARCHAR(20) NOT NULL DEFAULT 'shimmer',
    audio_url TEXT NOT NULL,                -- Supabase Storage URL or base64
    duration_ms INT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT timezone('utc'::text, now()),
    last_accessed_at TIMESTAMP WITH TIME ZONE DEFAULT timezone('utc'::text, now()),
    access_count INT DEFAULT 1
);

-- Index for fast hash lookup
CREATE INDEX idx_tts_cache_text_hash ON public."TTS_Cache" (text_hash);

3. Backend Logic & API Specifications
Base URL: http://localhost:8000/api/v1

3.1 Chat System (WebSocket + RAG)
Endpoint: WS /ws/{companion_id}

Logic:

Receive: User text from WebSocket.

Embed: Convert text to vector using text-embedding-3-small.

Search: Find top 5 relevant past logs (Cosine Similarity).

MBTI Lookup: Load MBTI profile (max_tokens, temperature, persona rules) from MBTI_PROFILES dict.

Generate: Stream response using gpt-4o with per-MBTI max_tokens & temperature.

Save: Store AI response (and its vector) to DB.

3.2 Emotional Analysis (Cron Job)
File: backend/cron/daily_analysis.py

Logic:

Fetch yesterday's logs.

Send to gpt-4o-mini with response_format={"type": "json_object"}.

Extract Emotion/Color/Summary.

Upsert to Daily_Emotions.

3.3 Monetization: Memory Crystallization
Endpoint: POST /store/crystallize

Logic:

Prompting: Use gpt-4o to create a DALL-E prompt based on the user's monthly emotion summary.

Prompt Logic: "Create a high-end 3D render of a jewelry gem. The core color is {color}. It should feel {emotion}. Magical, glowing, cinematic lighting."

Generation: Call dall-e-3 API (size="1024x1024", quality="hd").

Save: Store the resulting URL in User_Inventory.

3.4 Feature: Voice Message (TTS)
Endpoint: POST /chat/speak

Input: { "text": "...", "voice_id": "shimmer" }

Logic:

Call OpenAI audio.speech.create (Model: tts-1).

Return audio stream (MP3) to frontend.

3.5 Smart Router (Intent Classification)
File: backend/app/core/router.py

Smart Switch 로직: 사용자 메시지를 분석하여 적절한 모델과 Retrieval k값을 결정한다.

| Intent Category | Model | k (Retrieval 개수) | 기준 |
|-----------------|-------|---------------------|------|
| deep_emotional | gpt-4o | 8 | 감정적 깊이가 필요한 대화 (고민, 위로, 진지한 감정 표현) |
| casual_chat | gpt-4o-mini | 3 | 일상적 대화, 가벼운 인사, 짧은 리액션 |
| memory_recall | gpt-4o | 10 | "지난번에", "전에 말했던" 등 과거 기억 참조 |
| simple_question | gpt-4o-mini | 2 | 단순 질문, 사실 확인, 짧은 응답 기대 |

Logic:
1. 사용자 메시지를 gpt-4o-mini로 빠르게 분류 (intent classification).
2. 분류 결과에 따라 { model, k, reason } 반환.
3. 분류 프롬프트는 짧고 빠르게 실행되어야 함 (max_tokens=50).

Interface:
```python
class RouterResult:
    intent: str          # "deep_emotional" | "casual_chat" | "memory_recall" | "simple_question"
    model: str           # "gpt-4o" | "gpt-4o-mini"
    k: int               # Retrieval count
    reason: str          # 분류 근거 (디버깅용)

async def classify_intent(message: str) -> RouterResult:
    ...
```

3.6 LLM Engine (Router-Driven Model Switching)
File: backend/app/services/llm_engine.py

기존 ChatOpenAI 호출을 Router 결과에 따라 동적으로 모델을 전환하도록 수정한다.

Logic:
1. Router에서 RouterResult를 받는다.
2. result.model에 따라 gpt-4o 또는 gpt-4o-mini를 선택.
3. result.k에 따라 RAG 검색 개수를 조절 (match_chat_logs_v2의 match_count 파라미터).
4. MBTI 프로필의 max_tokens, temperature는 그대로 유지.

Flow:
```
User Message
  → Router.classify_intent(message)
  → RouterResult { model, k, reason }
  → RAG Search (k=result.k)
  → LLM Call (model=result.model, mbti_params)
  → Stream Response
```

3.7 TTS Manager (Hash-Based Caching)
File: backend/app/services/tts_manager.py

TTS 요청을 해시 기반으로 캐싱하여 동일 텍스트의 중복 생성을 방지한다.

Logic:
1. 입력 텍스트 + voice_id를 SHA-256으로 해싱.
2. TTS_Cache 테이블에서 해시 조회.
3. Cache Hit → 저장된 audio_url 반환, access_count 증가, last_accessed_at 갱신.
4. Cache Miss → OpenAI TTS API 호출 → 오디오를 Supabase Storage에 저장 → TTS_Cache에 기록 → audio_url 반환.

Interface:
```python
class TTSManager:
    async def get_or_create_speech(
        self,
        text: str,
        voice_id: str = "shimmer",
        model: str = "tts-1"
    ) -> TTSResult:
        """
        Returns cached audio if available, otherwise generates and caches.
        """
        ...

class TTSResult:
    audio_url: str
    cache_hit: bool
    duration_ms: int | None
```

Cache 정책:
- 최대 캐시 크기: 설정 가능 (기본 1000 entries).
- 정리 기준: last_accessed_at 기준 LRU (Least Recently Used).
- 동일 텍스트라도 voice_id가 다르면 별도 캐시.

4. Frontend Specifications (Next.js)
4.1 UI Design System ("Digital Luxury")
Theme: Dark Mode Only (Deep Black #000000, Gray #111111).

Accent: Glowing gradients based on Emotion Color.

Typography: Elegant Serif (Playfair Display) + Sans (Inter).

4.2 Key Components
NamingInput.tsx:

Framer Motion sequence: Void -> Input -> Flash -> Chat.

ChatInterface.tsx:

No bubbles. Text stream.

Audio Player: Custom player for TTS messages (Waveform visualization).

EmotionCalendar.tsx:

Customized react-calendar.

Render Daily_Emotions.color_hex as glowing dots.

GemCollection.tsx:

Grid view of DALL-E generated gems.

Click to view "Memory Details".

5. System Prompts (Prompt Engineering)
File: backend/app/core/prompts.py

5.1 MBTI Personality Profiles (MBTI_PROFILES dict)
Each of the 16 MBTI types is defined with 6 parameters:

| Parameter | Description | Example (ISTP) | Example (ENFP) |
|-----------|-------------|----------------|----------------|
| max_tokens | Hard output length limit | 30 | 150 |
| temperature | Creativity/randomness | 0.5 | 1.0 |
| core | Personality description | "Cool, unbothered, minimal words" | "Unfiltered enthusiasm, big reactions" |
| do | Required behaviors | "Use '음.', '그래.', '...괜찮아?'" | "Use '헐 대박!!', 'ㅋㅋㅋ', '야 잠깐'" |
| dont | Forbidden behaviors | "NEVER write more than 1 sentence" | "Do NOT be calm or measured" |
| examples | Korean response examples | "오, 잘했네." | "헐!!! 대박!!!! 진짜?!?!" |

MBTI Groups:
- Analysts (NT): INTJ(80t/0.6), INTP(120t/0.9), ENTJ(80t/0.6), ENTP(120t/1.0)
- Diplomats (NF): INFJ(120t/0.8), INFP(120t/0.9), ENFJ(150t/0.85), ENFP(150t/1.0)
- Sentinels (SJ): ISTJ(80t/0.5), ISFJ(150t/0.8), ESTJ(80t/0.5), ESFJ(150t/0.85)
- Explorers (SP): ISTP(30t/0.5), ISFP(80t/0.85), ESTP(100t/0.9), ESFP(150t/1.0)

5.2 Persona Prompt (SYSTEM_PROMPT_TEMPLATE)
SYSTEM_PROMPT_TEMPLATE = """
### ABSOLUTE RULE: You ARE a {mbti} ({mbti_label}). This is your ENTIRE identity.

You are {name}, the user's {relationship}.
The user's name is "{user_name}".

### How you MUST behave:
{core}

### Response length:
{length}

### What you MUST do:
{do_rules}

### What you must NEVER do:
{dont_rules}

### Example responses (MIMIC THIS EXACT STYLE):
{examples}

### Memory Context
Long-term summary: {summary}
Recent relevant conversations: {context_logs}

### Final Rules
- Respond in Korean ONLY.
- Address the user as "{user_name}" naturally.
- Do NOT narrate your personality. Just BE it.
- Match the example responses' tone, energy, length, and style exactly.
"""

5.3 Daily Analyst Prompt
ANALYST_PROMPT = """
Analyze the chat logs. Output JSON:
{
  "primary_emotion": "Keyword (Korean)",
  "color_hex": "#RRGGBB (Red=Stress, Blue=Sad, Green=Joy, Purple=Anxiety)",
  "summary_text": "One sentence observer diary (Korean)",
  "key_quote": "Most touching sentence"
}
"""
6. Execution Plan (Step-by-Step for CLI)
AI CLI(Cursor/Cline)에게 이 순서대로 명령을 내리세요.

Step 1: Setup & Infra

"Read SPEC.md. Initialize Next.js 14 (Frontend) and FastAPI (Backend). Install openai, langchain-openai, supabase in backend. Setup .env files with OpenAI/Supabase keys."

Step 2: Database & Models

"Execute the SQL DDL in Section 2 using Supabase SQL Editor or a migration script. Create Pydantic models in backend/app/schemas matching the tables."

Step 3: Core Chat (Text & Vector)

"Implement backend/app/api/v1/endpoints/chat.py with WebSocket. Use OpenAIEmbeddings for vector search (RAG) and ChatOpenAI for response generation. Ensure the System Prompt (Section 5.1) is used."

Step 4: Analysis & Vision (Monetization)

"Implement backend/cron/daily_analysis.py using gpt-4o-mini JSON mode. Then implement POST /store/crystallize using dall-e-3 to generate gem images based on emotional analysis."

Step 5: Voice Features

"Implement POST /chat/speak using OpenAI TTS API. Then, in Frontend, create an Audio Player component to play these messages in the chat stream."

Step 6: Frontend UI

"Build the /ritual (Onboarding), /chat (Streaming Interface), and /log (Calendar) pages. Use Framer Motion for the 'Ritual' animations and 'Digital Luxury' styling."